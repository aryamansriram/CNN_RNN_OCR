{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_valid(root_dir,folder):\n",
    "    '''Converts train test and valid lst files\n",
    "    to dataframe\n",
    "    args: root_dir: root directory\n",
    "    folder: name of file in which the image filenames are\n",
    "    '''\n",
    "    \n",
    "    train_dict = {}\n",
    "    train_dict[\"image\"] = []\n",
    "    train_dict[\"latex_line\"] = []\n",
    "    with open(root_dir+folder) as f:\n",
    "        arr = f.readlines()\n",
    "    for record in arr:\n",
    "        temp = record.split()\n",
    "        train_dict[\"image\"].append(temp[0])\n",
    "        train_dict[\"latex_line\"].append(temp[1])\n",
    "    train_df = pd.DataFrame(train_dict)\n",
    "    return train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>latex_line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7944775fc9.png</td>\n",
       "      <td>32771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78228211ca.png</td>\n",
       "      <td>32772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15b9034ba8.png</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6968dfca15.png</td>\n",
       "      <td>14185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6cead0df53.png</td>\n",
       "      <td>98321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            image latex_line\n",
       "0  7944775fc9.png      32771\n",
       "1  78228211ca.png      32772\n",
       "2  15b9034ba8.png         11\n",
       "3  6968dfca15.png      14185\n",
       "4  6cead0df53.png      98321"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = \"data/\"\n",
    "train = \"train.lst\"\n",
    "test = \"test.lst\"\n",
    "valid = \"valid.lst\"\n",
    "train_df = get_train_test_valid(root_dir,train)\n",
    "val_df = get_train_test_valid(root_dir,test)\n",
    "test_df = get_train_test_valid(root_dir,valid)\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_latex(root_dir,latex_folder,df):\n",
    "    '''Added latex expression to dataframe\n",
    "    args: root_dir: Root directory\n",
    "          latex_folder: Folder containing latex expressions\n",
    "          df: train/test/valid dataframe in question\n",
    "    returns: new dataframe with latex expressions added\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    with open(root_dir+latex_folder) as f:\n",
    "        arr = f.readlines()\n",
    "    latex = []\n",
    "    for index in df.latex_line.values:\n",
    "\n",
    "        latex.append(arr[(int)(index)])\n",
    "    df[\"latex_exp\"] = latex\n",
    "    return df\n",
    "\n",
    "train_df = add_latex(root_dir,\"formulas.norm.lst\",train_df)\n",
    "val_df = add_latex(root_dir,\"formulas.norm.lst\",val_df)\n",
    "test_df = add_latex(root_dir,\"formulas.norm.lst\",test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"data/latex_vocab.txt\") as f:\n",
    "    vocab = f.read().split(\"\\n\")\n",
    "word2index = {\"SOS\":0,\"EOS\":1}\n",
    "for i in range(len(vocab)):\n",
    "    word2index[vocab[i]] = i+2\n",
    "index2word = {0:\"SOS\",1:\"EOS\"}\n",
    "for i in range(len(vocab)):\n",
    "    index2word[i+2] = vocab[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>latex_line</th>\n",
       "      <th>latex_exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60ee748793.png</td>\n",
       "      <td>1</td>\n",
       "      <td>d s ^ { 2 } = ( 1 - { \\frac { q c o s \\theta }...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66667cee5b.png</td>\n",
       "      <td>2</td>\n",
       "      <td>\\widetilde \\gamma _ { \\mathrm { h o p f } } \\s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1cbb05a562.png</td>\n",
       "      <td>3</td>\n",
       "      <td>( { \\cal L } _ { a } g ) _ { i j } = 0 , \\ \\ \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ed164cc822.png</td>\n",
       "      <td>4</td>\n",
       "      <td>S _ { s t a t } = 2 \\pi \\sqrt { N _ { 5 } ^ { ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e265f9dc6b.png</td>\n",
       "      <td>5</td>\n",
       "      <td>\\hat { N } _ { 3 } = \\sum \\sp f _ { j = 1 } a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            image latex_line  \\\n",
       "0  60ee748793.png          1   \n",
       "1  66667cee5b.png          2   \n",
       "2  1cbb05a562.png          3   \n",
       "3  ed164cc822.png          4   \n",
       "4  e265f9dc6b.png          5   \n",
       "\n",
       "                                           latex_exp  \n",
       "0  d s ^ { 2 } = ( 1 - { \\frac { q c o s \\theta }...  \n",
       "1  \\widetilde \\gamma _ { \\mathrm { h o p f } } \\s...  \n",
       "2  ( { \\cal L } _ { a } g ) _ { i j } = 0 , \\ \\ \\...  \n",
       "3  S _ { s t a t } = 2 \\pi \\sqrt { N _ { 5 } ^ { ...  \n",
       "4  \\hat { N } _ { 3 } = \\sum \\sp f _ { j = 1 } a ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset,SequentialSampler\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "\n",
    "class OCR_Dataset(Dataset):\n",
    "    '''Custom dataset for latex images'''\n",
    "    def __init__(self,csv,root_dir,transforms=None):\n",
    "        self.csv = csv\n",
    "        self.transforms = transforms\n",
    "        self.root_dir = root_dir\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "    def __getitem__(self,idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx.to_list()\n",
    "        req = self.csv.iloc[idx]\n",
    "        img_name = req.image\n",
    "        latex = \"SOS \"+req.latex_exp+\" EOS\"\n",
    "        \n",
    "        encoding = [word2index[i] for i in latex.split()]\n",
    "        path = self.root_dir+img_name\n",
    "        img = cv2.imread(path)\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "        sample = {\"img\":img,\"label\":latex,\"encoding\":torch.tensor(encoding)}\n",
    "        return sample\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_dset = OCR_Dataset(train_df,root_dir = \"data/images_processed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img': array([[[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]]], dtype=uint8), 'label': 'SOS d s ^ { 2 } = ( 1 - { \\\\frac { q c o s \\\\theta } { r } } ) ^ { \\\\frac { 2 } { 1 + \\\\alpha ^ { 2 } } } \\\\lbrace d r ^ { 2 } + r ^ { 2 } d \\\\theta ^ { 2 } + r ^ { 2 } s i n ^ { 2 } \\\\theta d \\\\varphi ^ { 2 } \\\\rbrace - { \\\\frac { d t ^ { 2 } } { ( 1 - { \\\\frac { q c o s \\\\theta } { r } } ) ^ { \\\\frac { 2 } { 1 + \\\\alpha ^ { 2 } } } } } \\\\, .\\n EOS', 'encoding': tensor([  0, 470, 488, 463, 497,  23, 499,  37,   6,  22,  11, 497, 207, 497,\n",
      "        486, 468, 483, 488, 418, 499, 497, 487, 499, 499,   7, 463, 497, 207,\n",
      "        497,  23, 499, 497,  22,   9, 123, 463, 497,  23, 499, 499, 499, 242,\n",
      "        470, 487, 463, 497,  23, 499,   9, 487, 463, 497,  23, 499, 470, 418,\n",
      "        463, 497,  23, 499,   9, 487, 463, 497,  23, 499, 488, 475, 482, 463,\n",
      "        497,  23, 499, 418, 470, 436, 463, 497,  23, 499, 346,  11, 497, 207,\n",
      "        497, 470, 489, 463, 497,  23, 499, 499, 497,   6,  22,  11, 497, 207,\n",
      "        497, 486, 468, 483, 488, 418, 499, 497, 487, 499, 499,   7, 463, 497,\n",
      "        207, 497,  23, 499, 497,  22,   9, 123, 463, 497,  23, 499, 499, 499,\n",
      "        499, 499,  76,  14,   1])}\n"
     ]
    }
   ],
   "source": [
    "sample = ocr_dset[0]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "plt.imshow(sample[\"img\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    '''Definition of the convnet part of the paper'''\n",
    "    def __init__(self):\n",
    "        super(ConvNet,self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "                    nn.Conv2d(3,512,kernel_size=3,stride=1),\n",
    "                    nn.BatchNorm2d(512)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "                    nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n",
    "                    nn.BatchNorm2d(512),\n",
    "                    nn.MaxPool2d(kernel_size=(1,2),stride=(1,2))\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "                    nn.Conv2d(512,256,kernel_size=3,stride=1,padding=1),\n",
    "                    nn.MaxPool2d(kernel_size=(2,1),stride=(2,1))\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "                    nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "                    nn.BatchNorm2d(256)\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "                    nn.Conv2d(256,128,kernel_size=3,stride=1,padding=1),\n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        )\n",
    "        self.final = nn.Sequential(\n",
    "                nn.Conv2d(128,64,kernel_size=3,stride=1,padding=1),\n",
    "                nn.MaxPool2d(kernel_size=2,stride=2,padding=1)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        out = F.relu(self.final(x))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rowEncoder(nn.Module):\n",
    "    '''Definition of rowEncoder part of the network'''\n",
    "    def __init__(self,inp_dim,hidden_dim):\n",
    "        super(rowEncoder,self).__init__()\n",
    "        self.inp_dim = inp_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(self.inp_dim,self.hidden_dim,num_layers=1,batch_first=False,bidirectional=True)\n",
    "    \n",
    "    def forward(self,x,hidden):\n",
    "    \n",
    "        outputs,(hidden,cell) = self.lstm(x,hidden)\n",
    "\n",
    "        return outputs,hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size=1):\n",
    "        return (torch.zeros(2, batch_size, self.hidden_dim),\n",
    "                torch.zeros(2, batch_size, self.hidden_dim))\n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Decoder#####\n",
    "class BahadanauDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,hidden_size,output_size,n_layers=1):\n",
    "        super(BahadanauDecoder,self).__init__()\n",
    "        self.hidden_size=hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size*2)\n",
    "        self.fc_hidden = nn.Linear(self.hidden_size,self.hidden_size)\n",
    "        self.fc_encoder = nn.Linear(self.hidden_size*2,self.hidden_size)\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(13,self.hidden_size))\n",
    "        self.attn_combine = nn.Linear(self.hidden_size*2,self.hidden_size)\n",
    "        self.lstm = nn.LSTM(self.hidden_size*4,self.hidden_size,batch_first=False)\n",
    "        self.classifier = nn.Linear(self.hidden_size,self.output_size)\n",
    "    \n",
    "    \n",
    "    def forward(self,inputs,hidden,encoder_outputs):\n",
    "        encoder_outputs = encoder_outputs.squeeze()\n",
    "        embedded = self.embedding(inputs).view(1, -1)\n",
    "        print(\"enc ops\",encoder_outputs.size())\n",
    "        print(\"Hidden: \",hidden[0].size())\n",
    "        #print(encoder_outputs.size())\n",
    "        x = torch.tanh(self.fc_hidden(hidden[0].unsqueeze(0))+self.fc_encoder(encoder_outputs))\n",
    "        print(\"X: \",x.size())\n",
    "        x = x.permute(1,0,2)\n",
    "        print(\"enc outputs mul: \",self.fc_encoder(encoder_outputs).size())\n",
    "        print(\"Hidden Mul: \",self.fc_hidden(hidden[0]).size())\n",
    "        print(\"weights: \",self.weight.size())\n",
    "        \n",
    "        scores = x.bmm(self.weight.unsqueeze(2))\n",
    "        print(scores.size())\n",
    "        attn_weights = F.softmax(scores,dim=1)\n",
    "        \n",
    "        context_vector = torch.bmm(attn_weights.permute(0,2,1),encoder_outputs.permute(1,0,2))\n",
    "        \n",
    "        print(embedded.size())\n",
    "        print(\"CV: \",context_vector.size())\n",
    "        print(embedded.long().repeat(13,1).size())\n",
    "        output = torch.cat((embedded.long().repeat(13,1), context_vector.long().squeeze(1)), 1).unsqueeze(0)\n",
    "        print(hidden[0].unsqueeze(0).size())\n",
    "        hid = hidden[0].unsqueeze(0).unsqueeze(0)\n",
    "        output, hidden = self.lstm(output,hid)\n",
    "        \n",
    "        output = F.log_softmax(self.classifier(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define dataloaders###\n",
    "from torchvision import transforms\n",
    "trans = transforms.Compose([transforms.ToPILImage(),transforms.Resize((100,240)),transforms.ToTensor()])\n",
    "train_dataset = OCR_Dataset(train_df,root_dir = \"data/images_processed/\",transforms=trans)\n",
    "train_sampler = SequentialSampler(train_dataset)\n",
    "train_loader = DataLoader(train_dataset,batch_size=1,sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define model and its optimizer ####\n",
    "from torch.optim import Adam\n",
    "torch.manual_seed(42)\n",
    "conv = ConvNet()\n",
    "enc = rowEncoder(64,128)\n",
    "optim = Adam(conv.parameters(),lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 13, 128])\n",
      "tensor(0)\n",
      "enc ops torch.Size([30, 13, 256])\n",
      "Hidden:  torch.Size([13, 128])\n",
      "X:  torch.Size([30, 13, 128])\n",
      "enc outputs mul:  torch.Size([30, 13, 128])\n",
      "Hidden Mul:  torch.Size([13, 128])\n",
      "weights:  torch.Size([13, 128])\n",
      "torch.Size([13, 30, 1])\n",
      "torch.Size([1, 256])\n",
      "CV:  torch.Size([13, 1, 256])\n",
      "torch.Size([13, 256])\n",
      "torch.Size([1, 13, 128])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-457-ea29b6c08377>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-455-31d4e34c91c8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mhid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    499\u001b[0m         self.check_hidden_size(hidden[0], expected_hidden_size,\n\u001b[1;32m    500\u001b[0m                                'Expected hidden[0] size {}, got {}')\n\u001b[0;32m--> 501\u001b[0;31m         self.check_hidden_size(hidden[1], expected_hidden_size,\n\u001b[0m\u001b[1;32m    502\u001b[0m                                'Expected hidden[1] size {}, got {}')\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "### Testing area ####\n",
    "count = 0\n",
    "\n",
    "for num,batch in enumerate(train_loader):\n",
    "    img,label,encoding = batch[\"img\"],batch[\"label\"],batch[\"encoding\"]\n",
    "    output = conv(img)\n",
    "    \n",
    "    output = output.squeeze(0)\n",
    "    output = output.permute(2,1,0)\n",
    "    h = enc.init_hidden(batch_size=13)\n",
    "    outputs,hidden = enc(output,h)\n",
    "    print(hidden.size())\n",
    "    \n",
    "    dec_hidden = hidden\n",
    "    \n",
    "    for i in encoding[0]:\n",
    "        print(i)\n",
    "        a,b,c = dec(i,dec_hidden,outputs)\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 13, 256])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index = {}\n",
    "for i in range(len(vocab)):\n",
    "    word2index[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for exp in train_df.latex_exp:\n",
    "    if len(exp.split())>max_len:\n",
    "        max_len=len(exp.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = BahadanauDecoder(128,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 1])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 4])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.repeat(5,1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
